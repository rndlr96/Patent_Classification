name: pre_word2vec

model:
  hidden_size: 512
  layers_num: 2
  linear_size: [256]
  dropout: 0.5

train:
  batch_size: 256
  nb_epoch: 30
  swa_warmup: 10

valid:
  batch_size: 256

predict:
  batch_size: 256

path: models
